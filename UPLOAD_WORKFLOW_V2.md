# PDF 上传和处理流程 v2.0

## 🎯 新流程设计理念

### 核心原则
1. **本地和云端状态一致**：通过同步机制保持文件夹结构完全一致
2. **增量上传**：只上传新文件，避免重复和冲突
3. **逻辑分离**：本地操作和云端处理完全独立

---

## 📋 完整工作流程

### 1️⃣ 本地操作：同步 + 增量上传

#### 步骤 1: 放入新 PDF
```bash
# 将新的 PDF 文件复制到 pdfs_to_process/
cp ~/Downloads/*.pdf pdfs_to_process/
```

#### 步骤 2: 执行智能上传脚本
```bash
./upload-pdfs-v2.sh
```

#### 脚本自动执行的操作

**阶段 1: 同步云端状态**
```
1. git pull 拉取最新状态
2. 对比本地和云端的 pdfs_to_process/
3. 找出已被云端处理的文件（本地有，云端没有）
4. 将这些文件移动到本地 public/pdfs/
5. 本地状态与云端完全一致
```

**阶段 2: 识别新文件**
```
1. 重新扫描本地 pdfs_to_process/
2. 对比云端 pdfs_to_process/
3. 找出本地新增的文件（本地有，云端没有）
4. 列出待上传的新文件
```

**阶段 3: 增量上传**
```
1. 只 git add 新文件
2. 提交并推送到 GitHub
3. 云端待处理队列增加
```

---

### 2️⃣ 云端处理：定时自动化

#### GitHub Actions 定时任务
- **触发时间**：每天早上 6:00（北京时间）
- **执行内容**：
  1. 从 `pdfs_to_process/` 取出第一个 PDF
  2. 调用 DeepSeek API 分析
  3. 生成文章数据（`src/data/articlesData.ts`）
  4. 移动 PDF 到 `public/pdfs/`
  5. 删除 `pdfs_to_process/` 中的原文件
  6. 自动提交并部署

---

## 🔄 典型使用场景

### 场景 1: 首次上传 5 个新 PDF

```bash
# 1. 放入 PDF
cp ~/Downloads/报告*.pdf pdfs_to_process/

# 2. 执行上传
./upload-pdfs-v2.sh
```

**输出示例**：
```
📥 步骤 1/4: 同步云端状态...
✅ 本地和云端状态一致，无需同步

📊 步骤 2/4: 识别需要上传的新文件...
🆕 发现 5 个新文件需要上传:
   - 报告1.pdf
   - 报告2.pdf
   - 报告3.pdf
   - 报告4.pdf
   - 报告5.pdf

是否继续上传这 5 个新文件到 GitHub？(y/n) y

🚀 步骤 3/4: 增量上传新文件到 GitHub...
✅ 上传完成！

📊 步骤 4/4: 总结
本次操作:
  - 同步处理: 0 个文件
  - 新增上传: 5 个文件

云端待处理队列:
  - 上传前: 0 个文件
  - 上传后: 5 个文件

🤖 接下来:
  - GitHub Actions 将在每天早上 6:00 自动处理一篇
  - 预计 5 天后全部处理完成
```

---

### 场景 2: 云端已处理 2 篇，再上传 3 篇新的

**初始状态**：
- 云端 `pdfs_to_process/`: 3 篇（剩余）
- 本地 `pdfs_to_process/`: 5 篇（3 篇旧 + 2 篇已被云端处理但本地还在）

**操作**：
```bash
# 1. 放入 3 篇新 PDF
cp ~/Downloads/新报告*.pdf pdfs_to_process/

# 现在本地有: 5 篇旧 + 3 篇新 = 8 篇

# 2. 执行上传
./upload-pdfs-v2.sh
```

**输出示例**：
```
📥 步骤 1/4: 同步云端状态...
🔄 发现 2 个文件已被云端处理，需要同步到本地 public/pdfs/...
   移动: 报告1.pdf
   移动: 报告2.pdf
✅ 本地同步完成

📊 步骤 2/4: 识别需要上传的新文件...
🆕 发现 3 个新文件需要上传:
   - 新报告1.pdf
   - 新报告2.pdf
   - 新报告3.pdf

是否继续上传这 3 个新文件到 GitHub？(y/n) y

🚀 步骤 3/4: 增量上传新文件到 GitHub...
✅ 上传完成！

📊 步骤 4/4: 总结
本次操作:
  - 同步处理: 2 个文件
  - 新增上传: 3 个文件

云端待处理队列:
  - 上传前: 3 个文件
  - 上传后: 6 个文件
```

**结果**：
- 本地 `pdfs_to_process/`: 6 篇（3 篇旧 + 3 篇新）
- 本地 `public/pdfs/`: +2 篇（同步过来的）
- 云端 `pdfs_to_process/`: 6 篇（3 篇旧 + 3 篇新）

---

## 📊 目录结构说明

### 本地目录
```
pdfs_to_process/     ← 待上传/待处理（与云端同步）
public/pdfs/         ← 已发布（与云端同步）
pdfs_archived/       ← 本地归档（已废弃，不再使用）
```

### 云端目录（GitHub）
```
pdfs_to_process/     ← 待处理队列
public/pdfs/         ← 已发布（网页读取）
```

---

## ✅ 新流程的优势

### 1. 状态一致性
- ✅ 本地和云端文件夹结构完全一致
- ✅ 不会出现文件位置混乱
- ✅ 随时可以通过 `git pull` 同步最新状态

### 2. 增量上传
- ✅ 只上传真正的新文件
- ✅ 不会重复上传已存在的文件
- ✅ 节省带宽和时间

### 3. 自动同步
- ✅ 脚本自动识别已处理的文件
- ✅ 自动移动到正确的位置
- ✅ 无需手动管理

### 4. 清晰的队列管理
- ✅ 实时显示待处理队列大小
- ✅ 预估处理完成时间
- ✅ 避免重复处理

---

## 🔧 与旧版本的对比

### 旧版本（upload-pdfs.sh）
```
1. 上传所有本地文件到云端
2. 移动到本地 pdfs_archived/
3. 问题：不检查云端状态，可能重复上传
```

### 新版本（upload-pdfs-v2.sh）
```
1. 先同步云端状态（git pull）
2. 对比本地和云端，识别已处理的文件
3. 移动已处理的文件到 public/pdfs/
4. 只上传新文件
5. 显示详细的统计信息
```

---

## 🚀 快速开始

### 第一次使用
```bash
# 1. 确保脚本可执行
chmod +x upload-pdfs-v2.sh

# 2. 放入 PDF
cp ~/Downloads/*.pdf pdfs_to_process/

# 3. 执行上传
./upload-pdfs-v2.sh
```

### 日常使用
```bash
# 每次有新 PDF 时
cp ~/Downloads/新报告.pdf pdfs_to_process/
./upload-pdfs-v2.sh
```

---

## 📝 注意事项

1. **首次使用前**：确保本地仓库是最新的（`git pull`）
2. **文件命名**：避免使用特殊字符，建议使用中文或英文
3. **文件大小**：单个文件建议不超过 50MB
4. **处理时间**：云端每天处理一篇，合理安排上传时间

---

## 🎉 总结

新流程实现了：
- ✅ 本地和云端完全同步
- ✅ 智能增量上传
- ✅ 自动状态管理
- ✅ 清晰的队列可视化

**现在就试试新的上传脚本吧！** 🚀

